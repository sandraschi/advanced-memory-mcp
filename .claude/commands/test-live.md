# /project:test-live - Live Basic Memory Testing Suite

Execute comprehensive real-world testing of Basic Memory using the installed version. 
All test results are recorded as notes in a dedicated test project.

## Usage
```
/project:test-live [phase]
```

**Parameters:**
- `phase` (optional): Specific test phase to run (`recent`, `core`, `features`, `edge`, `workflows`, `stress`, or `all`)
- `recent` - Focus on recent changes and new features (recommended for regular testing)
- `core` - Essential tools only (Tier 1: write_note, read_note, search_notes, edit_note, list_projects, switch_project)
- `features` - Core + important workflows (Tier 1 + Tier 2)
- `all` - Comprehensive testing of all tools and scenarios

## Implementation

You are an expert QA engineer conducting live testing of Basic Memory. 
When the user runs `/project:test-live`, execute comprehensive test plan:

## Tool Testing Priority

### **Tier 1: Critical Core (Always Test)**
1. **write_note** - Foundation of all knowledge creation
2. **read_note** - Primary knowledge retrieval mechanism  
3. **search_notes** - Essential for finding information
4. **edit_note** - Core content modification capability
5. **list_memory_projects** - Project discovery and status
6. **switch_project** - Context switching for multi-project workflows

### **Tier 2: Important Workflows (Usually Test)**
7. **recent_activity** - Understanding what's changed
8. **build_context** - Conversation continuity via memory:// URLs
9. **create_memory_project** - Essential for project setup
10. **move_note** - Knowledge organization
11. **sync_status** - Understanding system state

### **Tier 3: Enhanced Functionality (Sometimes Test)**
12. **view_note** - Claude Desktop artifact display
13. **read_content** - Raw content access
14. **delete_note** - Content removal
15. **list_directory** - File system exploration
16. **set_default_project** - Configuration
17. **delete_project** - Administrative cleanup

### **Tier 4: Specialized (Rarely Test)**
18. **canvas** - Obsidian visualization (specialized use case)
19. **MCP Prompts** - Enhanced UX tools (ai_assistant_guide, continue_conversation)

### Pre-Test Setup

1. **Environment Verification**
   - Verify basic-memory is installed and accessible via MCP
   - Check version and confirm it's the expected release
   - Test MCP connection and tool availability

2. **Recent Changes Analysis** (if phase includes 'recent' or 'all')
   - Run `git log --oneline -20` to examine recent commits
   - Identify new features, bug fixes, and enhancements
   - Generate targeted test scenarios for recent changes
   - Prioritize regression testing for recently fixed issues

3. **Test Project Creation**

Run the bash `date` command to get the current date/time. 

   ```
   Create project: "basic-memory-testing-[timestamp]"
   Location: ~/basic-memory-testing-[timestamp]
   Purpose: Record all test observations and results
   ```

Make sure to switch to the newly created project with the `switch_project()` tool.

4. **Baseline Documentation**
   Create initial test session note with:
   - Test environment details
   - Version being tested
   - Recent changes identified (if applicable)
   - Test objectives and scope
   - Start timestamp

### Phase 0: Recent Changes Validation (if 'recent' or 'all' phase)

Based on recent commit analysis, create targeted test scenarios:

**Recent Changes Test Protocol:**
1. **Feature Addition Tests** - For each new feature identified:
   - Test basic functionality
   - Test integration with existing tools
   - Verify documentation accuracy
   - Test edge cases and error handling

2. **Bug Fix Regression Tests** - For each recent fix:
   - Recreate the original problem scenario
   - Verify the fix works as expected
   - Test related functionality isn't broken
   - Document the verification in test notes

3. **Performance/Enhancement Validation** - For optimizations:
   - Establish baseline timing
   - Compare with expected improvements
   - Test under various load conditions
   - Document performance observations

**Example Recent Changes (Update based on actual git log):**
- Watch Service Restart (#156): Test project creation ‚Üí file modification ‚Üí automatic restart
- Cross-Project Moves (#161): Test move_note with cross-project detection
- Docker Environment Support (#174): Test BASIC_MEMORY_HOME behavior
- MCP Server Logging (#164): Verify log level configurations

### Phase 1: Core Functionality Validation (Tier 1 Tools)

Test essential MCP tools that form the foundation of Basic Memory:

**1. write_note Tests (Critical):**
- ‚úÖ Basic note creation with frontmatter
- ‚úÖ Special characters and Unicode in titles
- ‚úÖ Various content types (lists, headings, code blocks)
- ‚úÖ Empty notes and minimal content edge cases
- ‚ö†Ô∏è Error handling for invalid parameters

**2. read_note Tests (Critical):**
- ‚úÖ Read by title, permalink, memory:// URLs
- ‚úÖ Non-existent notes (error handling)
- ‚úÖ Notes with complex markdown formatting
- ‚ö†Ô∏è Performance with large notes (>10MB)

**3. search_notes Tests (Critical):**
- ‚úÖ Simple text queries across content
- ‚úÖ Tag-based searches with multiple tags
- ‚úÖ Boolean operators (AND, OR, NOT)
- ‚úÖ Empty/no results scenarios
- ‚ö†Ô∏è Performance with 100+ notes

**4. edit_note Tests (Critical):**
- ‚úÖ Append operations preserving frontmatter
- ‚úÖ Prepend operations
- ‚úÖ Find/replace with validation
- ‚úÖ Section replacement under headers
- ‚ö†Ô∏è Error scenarios (invalid operations)

**5. list_memory_projects Tests (Critical):**
- ‚úÖ Display all projects with status indicators
- ‚úÖ Current and default project identification
- ‚úÖ Empty project list handling
- ‚úÖ Project metadata accuracy

**6. switch_project Tests (Critical):**
- ‚úÖ Switch between existing projects
- ‚úÖ Context preservation during switch
- ‚ö†Ô∏è Invalid project name handling
- ‚úÖ Confirmation of successful switch

### Phase 2: Important Workflows (Tier 2 Tools)

**7. recent_activity Tests (Important):**
- ‚úÖ Various timeframes ("today", "1 week", "1d")
- ‚úÖ Type filtering capabilities
- ‚úÖ Empty project scenarios
- ‚ö†Ô∏è Performance with many recent changes

**8. build_context Tests (Important):**
- ‚úÖ Different depth levels (1, 2, 3+)
- ‚úÖ Various timeframes for context
- ‚úÖ memory:// URL navigation
- ‚ö†Ô∏è Performance with complex relation graphs

**9. create_memory_project Tests (Important):**
- ‚úÖ Create projects dynamically
- ‚úÖ Set default during creation
- ‚úÖ Path validation and creation
- ‚ö†Ô∏è Invalid paths and names
- ‚úÖ Integration with existing projects

**10. move_note Tests (Important):**
- ‚úÖ Move within same project
- ‚úÖ Cross-project moves with detection (#161)
- ‚úÖ Automatic folder creation
- ‚úÖ Database consistency validation
- ‚ö†Ô∏è Special characters in paths

**11. sync_status Tests (Important):**
- ‚úÖ Background operation monitoring
- ‚úÖ File synchronization status
- ‚úÖ Project sync state reporting
- ‚ö†Ô∏è Error state handling

### Phase 3: Enhanced Functionality (Tier 3 Tools)

**12. view_note Tests (Enhanced):**
- ‚úÖ Claude Desktop artifact display
- ‚úÖ Title extraction from frontmatter
- ‚úÖ Unicode and emoji content rendering
- ‚ö†Ô∏è Error handling for non-existent notes

**13. read_content Tests (Enhanced):**
- ‚úÖ Raw file content access
- ‚úÖ Binary file handling
- ‚úÖ Image file reading
- ‚ö†Ô∏è Large file performance

**14. delete_note Tests (Enhanced):**
- ‚úÖ Single note deletion
- ‚úÖ Database consistency after deletion
- ‚ö†Ô∏è Non-existent note handling
- ‚úÖ Confirmation of successful deletion

**15. list_directory Tests (Enhanced):**
- ‚úÖ Directory content listing
- ‚úÖ Depth control and filtering
- ‚úÖ File name globbing
- ‚ö†Ô∏è Empty directory handling

**16. set_default_project Tests (Enhanced):**
- ‚úÖ Change default project
- ‚úÖ Configuration persistence
- ‚ö†Ô∏è Invalid project handling

**17. delete_project Tests (Enhanced):**
- ‚úÖ Project removal from config
- ‚úÖ Database cleanup
- ‚ö†Ô∏è Default project protection
- ‚ö†Ô∏è Non-existent project handling

### Phase 4: Edge Case Exploration

**Boundary Testing:**
- Very long titles and content (stress limits)
- Empty projects and notes
- Unicode, emojis, special symbols
- Deeply nested folder structures
- Circular relations and self-references
- Maximum relation depths

**Error Scenarios:**
- Invalid memory:// URLs
- Missing files referenced in database
- Invalid project names and paths
- Malformed note structures
- Concurrent operation conflicts

**Performance Testing:**
- Create 100+ notes rapidly
- Complex search queries
- Deep relation chains (5+ levels)
- Rapid successive operations
- Memory usage monitoring

### Phase 5: Real-World Workflow Scenarios

**Meeting Notes Pipeline:**
1. Create meeting notes with action items
2. Extract action items using edit_note
3. Build relations to project documents
4. Update progress incrementally
5. Search and track completion

**Research Knowledge Building:**
1. Create research topic hierarchy
2. Build complex relation networks
3. Add incremental findings over time
4. Search for connections and patterns
5. Reorganize as knowledge evolves

**Multi-Project Workflow:**
1. Technical documentation project
2. Personal recipe collection project
3. Learning/course notes project
4. Switch contexts during conversation
5. Cross-reference related concepts

**Content Evolution:**
1. Start with basic notes
2. Enhance with relations and observations
3. Reorganize file structure using moves
4. Update content with edit operations
5. Validate knowledge graph integrity

### Phase 6: Specialized Tools Testing (Tier 4)

**18. canvas Tests (Specialized):**
- ‚úÖ JSON Canvas generation
- ‚úÖ Node and edge creation
- ‚úÖ Obsidian compatibility
- ‚ö†Ô∏è Complex graph handling

**19. MCP Prompts Tests (Specialized):**
- ‚úÖ ai_assistant_guide output
- ‚úÖ continue_conversation functionality
- ‚úÖ Formatted search results
- ‚úÖ Enhanced activity reports

### Phase 7: Integration & File Watching Tests

**File System Integration:**
- ‚úÖ Watch service behavior with file changes
- ‚úÖ Project creation ‚Üí watch restart (#156)
- ‚úÖ Multi-project synchronization
- ‚ö†Ô∏è MCP‚ÜíAPI‚ÜíDB‚ÜíFile stack validation

**Real Integration Testing:**
- ‚úÖ End-to-end file watching vs manual operations
- ‚úÖ Cross-session persistence
- ‚úÖ Database consistency across operations
- ‚ö†Ô∏è Performance under real file system changes

### Phase 8: Creative Stress Testing

**Creative Exploration:**
- Rapid project creation/switching patterns
- Unusual but valid markdown structures
- Creative observation categories
- Novel relation types and patterns
- Unexpected tool combinations

**Stress Scenarios:**
- Bulk operations (many notes quickly)
- Complex nested moves and edits
- Deep context building
- Complex boolean search expressions
- Resource constraint testing

## Test Execution Guidelines

### Quick Testing (core/features phases)
- Focus on Tier 1 tools (core) or Tier 1+2 (features)
- Test essential functionality and common edge cases
- Record critical issues immediately
- Complete in 15-20 minutes

### Comprehensive Testing (all phase)
- Cover all tiers systematically
- Include specialized tools and stress testing
- Document performance baselines
- Complete in 45-60 minutes

### Recent Changes Focus (recent phase)
- Analyze git log for recent commits
- Generate targeted test scenarios
- Focus on regression testing for fixes
- Validate new features thoroughly

## Test Observation Format

Record ALL observations immediately as Basic Memory notes:

```markdown
---
title: Test Session [Phase] YYYY-MM-DD HH:MM
tags: [testing, v0.13.0, live-testing, [phase]]
permalink: test-session-[phase]-[timestamp]
---

# Test Session [Phase] - [Date/Time]

## Environment
- Basic Memory version: [version]
- MCP connection: [status]
- Test project: [name]
- Phase focus: [description]

## Test Results

### ‚úÖ Successful Operations
- [timestamp] ‚úÖ write_note: Created note with emoji title üìù #tier1 #functionality
- [timestamp] ‚úÖ search_notes: Boolean query returned 23 results in 0.4s #tier1 #performance  
- [timestamp] ‚úÖ edit_note: Append operation preserved frontmatter #tier1 #reliability

### ‚ö†Ô∏è Issues Discovered
- [timestamp] ‚ö†Ô∏è move_note: Slow with deep folder paths (2.1s) #tier2 #performance
- [timestamp] üö® search_notes: Unicode query returned unexpected results #tier1 #bug #critical
- [timestamp] ‚ö†Ô∏è build_context: Context lost for memory:// URLs #tier2 #issue

### üöÄ Enhancements Identified
- edit_note could benefit from preview mode #ux-improvement
- search_notes needs fuzzy matching for typos #feature-idea
- move_note could auto-suggest folder creation #usability

### üìä Performance Metrics
- Average write_note time: 0.3s
- Search with 100+ notes: 0.6s
- Project switch overhead: 0.1s
- Memory usage: [observed levels]

## Relations
- tests [[Basic Memory v0.13.0]]
- part_of [[Live Testing Suite]]
- found_issues [[Bug Report: Unicode Search]]
- discovered [[Performance Optimization Opportunities]]
```

## Quality Assessment Areas

**User Experience & Usability:**
- Tool instruction clarity and examples
- Error message actionability
- Response time acceptability
- Tool consistency and discoverability
- Learning curve and intuitiveness

**System Behavior:**
- Context preservation across operations
- memory:// URL navigation reliability
- Multi-step workflow cohesion
- Edge case graceful handling
- Recovery from user errors

**Documentation Alignment:**
- Tool output clarity and helpfulness
- Behavior vs. documentation accuracy
- Example validity and usefulness
- Real-world vs. documented workflows

**Mental Model Validation:**
- Natural user expectation alignment
- Surprising behavior identification
- Mistake recovery ease
- Knowledge graph concept naturalness

**Performance & Reliability:**
- Operation completion times
- Consistency across sessions
- Scaling behavior with growth
- Unexpected slowness identification

## Error Documentation Protocol

For each error discovered:

1. **Immediate Recording**
   - Create dedicated error note
   - Include exact reproduction steps
   - Capture error messages verbatim
   - Note system state when error occurred

2. **Error Note Format**
   ```markdown
   ---
   title: Bug Report - [Short Description]
   tags: [bug, testing, v0.13.0, [severity]]
   ---
   
   # Bug Report: [Description]
   
   ## Reproduction Steps
   1. [Exact steps to reproduce]
   2. [Include all parameters used]
   3. [Note any special conditions]
   
   ## Expected Behavior
   [What should have happened]
   
   ## Actual Behavior  
   [What actually happened]
   
   ## Error Messages
   ```
   [Exact error text]
   ```
   
   ## Environment
   - Version: [version]
   - Project: [name]
   - Timestamp: [when]
   
   ## Severity
   - [ ] Critical (blocks major functionality)
   - [ ] High (impacts user experience)
   - [ ] Medium (workaround available)
   - [ ] Low (minor inconvenience)
   
   ## Relations
   - discovered_during [[Test Session [Phase]]]
   - affects [[Feature Name]]
   ```

## Success Metrics Tracking

**Quantitative Measures:**
- Test scenario completion rate
- Bug discovery count with severity
- Performance benchmark establishment
- Tool coverage completeness

**Qualitative Measures:**
- Conversation flow naturalness
- Knowledge graph quality
- User experience insights
- System reliability assessment

## Test Execution Flow

1. **Setup Phase** (5 minutes)
   - Verify environment and create test project
   - Record baseline system state
   - Establish performance benchmarks

2. **Core Testing** (15-20 minutes per phase)
   - Execute test scenarios systematically
   - Record observations immediately
   - Note timestamps for performance tracking
   - Explore variations when interesting behaviors occur

3. **Documentation** (5 minutes per phase)
   - Create phase summary note
   - Link related test observations
   - Update running issues list
   - Record enhancement ideas

4. **Analysis Phase** (10 minutes)
   - Review all observations across phases
   - Identify patterns and trends
   - Create comprehensive summary report
   - Generate development recommendations

## Testing Success Criteria

### Core Testing (Tier 1) - Must Pass
- All 6 critical tools function correctly
- No critical bugs in essential workflows
- Acceptable performance for basic operations
- Error handling works as expected

### Feature Testing (Tier 1+2) - Should Pass
- All 11 core + important tools function
- Workflow scenarios complete successfully
- Performance meets baseline expectations
- Integration points work correctly

### Comprehensive Testing (All Tiers) - Complete Coverage
- All tools tested across all scenarios
- Edge cases and stress testing completed
- Performance baselines established
- Full documentation of issues and enhancements

## Expected Outcomes

**System Validation:**
- Feature verification prioritized by tier importance
- Recent changes validated for regression
- Performance baseline establishment
- Bug identification with severity assessment

**Knowledge Base Creation:**
- Prioritized testing documentation
- Real usage examples for user guides
- Recent changes validation records
- Performance insights for optimization

**Development Insights:**
- Tier-based bug priority list
- Recent changes impact assessment
- Enhancement ideas from real usage
- User experience improvement areas

## Post-Test Deliverables

1. **Test Summary Note**
   - Overall results and findings
   - Critical issues requiring immediate attention
   - Enhancement opportunities discovered
   - System readiness assessment

2. **Bug Report Collection**
   - All discovered issues with reproduction steps
   - Severity and impact assessments
   - Suggested fixes where applicable

3. **Performance Baseline**
   - Timing data for all operations
   - Scaling behavior observations
   - Resource usage patterns

4. **UX Improvement Recommendations**
   - Usability enhancement suggestions
   - Documentation improvement areas
   - Tool design optimization ideas

5. **Updated TESTING.md**
   - Incorporate new test scenarios discovered
   - Update based on real execution experience
   - Add performance benchmarks and targets

## Context
- Uses real installed basic-memory version 
- Tests complete MCP‚ÜíAPI‚ÜíDB‚ÜíFile stack
- Creates living documentation in Basic Memory itself
- Follows integration over isolation philosophy
- Prioritizes testing by tool importance and usage frequency
- Adapts to recent development changes dynamically
- Focuses on real usage patterns over checklist validation
- Generates actionable insights prioritized by impact